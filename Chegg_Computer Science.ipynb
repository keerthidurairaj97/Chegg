{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "import io\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "from matplotlib import rcParams\n",
    "import seaborn as sns \n",
    "from scipy.stats import zscore\n",
    "from sklearn.linear_model import LinearRegression \n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, r2_score \n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "# switch to seaborn default stylistic parameters\n",
    "sns.set()\n",
    "sns.set_context('notebook') \n",
    "#Read the Kuiper's 2008 car data\n",
    "\n",
    "#We'll drop the Model and Trim features, as we are interested in making predictions without identifying the exact kind of car.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://raw.githubusercontent.com/grbruns/cst383/master/kuiper-2008-cars.csv\"\n",
    "raw=requests.get(url).content\n",
    "df=pd.read_csv(io.StringIO(raw.decode('utf-8')))\n",
    "df.drop(['Model', 'Trim'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting all categorical variables to numeric by Using pandas.get_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape before (804, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"shape before\",df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape after (804, 19)\n"
     ]
    }
   ],
   "source": [
    "print(\"shape after\",df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 804 entries, 0 to 803\n",
      "Data columns (total 19 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Price             804 non-null    float64\n",
      " 1   Mileage           804 non-null    int64  \n",
      " 2   Cylinder          804 non-null    int64  \n",
      " 3   Liter             804 non-null    float64\n",
      " 4   Doors             804 non-null    int64  \n",
      " 5   Cruise            804 non-null    int64  \n",
      " 6   Sound             804 non-null    int64  \n",
      " 7   Leather           804 non-null    int64  \n",
      " 8   Make_Buick        804 non-null    uint8  \n",
      " 9   Make_Cadillac     804 non-null    uint8  \n",
      " 10  Make_Chevrolet    804 non-null    uint8  \n",
      " 11  Make_Pontiac      804 non-null    uint8  \n",
      " 12  Make_SAAB         804 non-null    uint8  \n",
      " 13  Make_Saturn       804 non-null    uint8  \n",
      " 14  Type_Convertible  804 non-null    uint8  \n",
      " 15  Type_Coupe        804 non-null    uint8  \n",
      " 16  Type_Hatchback    804 non-null    uint8  \n",
      " 17  Type_Sedan        804 non-null    uint8  \n",
      " 18  Type_Wagon        804 non-null    uint8  \n",
      "dtypes: float64(2), int64(6), uint8(11)\n",
      "memory usage: 59.0 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's build a linear model in which we use all of the features as predictors, and look at the values of all the coefficients.\n",
    "\n",
    "#@ Make a model with all features. First, create X and y where y contains 'Price' values and X contains the other columns of df. Next, perform a test train split to get X_train, X_test, etc. Then create a linear model using LinearRegression.  Call your model reg5. Finally, print the coefficients of your model (use a loop in printing all coefficients except the intercept)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df['Price']\n",
    "X=df.drop(['Price'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(804, 18)\n",
      "(804,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performed train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg5 = LinearRegression()\n",
    "reg5.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#printing all co-efficient except intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept 24381.25120421961\n",
      "The coefficient for Mileage is -0.18866401986252573\n",
      "The coefficient for Cylinder is -1083.7314516474241\n",
      "The coefficient for Liter is 5516.671090142473\n",
      "The coefficient for Doors is -2111.1571748414913\n",
      "The coefficient for Cruise is 46.92629184544157\n",
      "The coefficient for Sound is 312.91010690041156\n",
      "The coefficient for Leather is 201.4515278548885\n",
      "The coefficient for Make_Buick is -3605.154414258059\n",
      "The coefficient for Make_Cadillac is 12681.304751536256\n",
      "The coefficient for Make_Chevrolet is -5526.686848128268\n",
      "The coefficient for Make_Pontiac is -5406.748381338428\n",
      "The coefficient for Make_SAAB is 6739.172934639635\n",
      "The coefficient for Make_Saturn is -4881.888042451127\n",
      "The coefficient for Type_Convertible is 6645.217168619957\n",
      "The coefficient for Type_Coupe is -5589.6385811992095\n",
      "The coefficient for Type_Hatchback is -1724.2878207654387\n",
      "The coefficient for Type_Sedan is -1630.9970931924336\n",
      "The coefficient for Type_Wagon is 2299.706326537131\n"
     ]
    }
   ],
   "source": [
    "print(\"Intercept\",reg5.intercept_)\n",
    "for idx, col_name in enumerate(X_train.columns):\n",
    "    print(\"The coefficient for {} is {}\".format(col_name, reg5.coef_[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "##@  Print the r-squared value for your model based on the training data and also print the RMSE based on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score 0.9377078006373982\n"
     ]
    }
   ],
   "source": [
    "y_pred = reg5.predict(X_test)\n",
    "r2_score=r2_score(y_test,y_pred)\n",
    "print(\"r2_score\",r2_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean squared 2346.2905173925437\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(y_test, y_pred)\n",
    "from math import sqrt\n",
    "rms = sqrt(mse)\n",
    "print(\"Root mean squared\",rms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can add even more features to the model by adding derived features. Let's try the PolynomialFeatures class.\n",
    "\n",
    "#@ From your NumPy array X create an extended data set X_poly using PolynomialFeatures with degree=2.\n",
    "#Assign your PolynomialFeatures object to variable pf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=2, interaction_only=True)\n",
    "X_poly = poly.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## reg6 model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_poly, y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg6 = LinearRegression()\n",
    "reg6.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#printing all co-efficient except intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean squared 1602.6613457057192\n"
     ]
    }
   ],
   "source": [
    "y_pred = reg6.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "from math import sqrt\n",
    "rms = sqrt(mse)\n",
    "print(\"Root mean squared\",rms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_0 = X_train[:,[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute negated mean square error scores using 5-fold cross validation\n",
    "scores = cross_val_score(LinearRegression(), X_0, y_train, scoring='neg_mean_squared_error', cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# work out the average root mean squared error.  We need to first negate the scores, because they are negative MSE, not MSE.\n",
    "rmse = np.sqrt(-scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for feature 0 only: 10087.54\n"
     ]
    }
   ],
   "source": [
    "print('RMSE for feature 0 only: {:.2f}'. format(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RMSE for each scoreand K-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2938027.39378651 -2259773.28294089 -2272890.58908102 -2550797.38765178\n",
      " -4366738.55350587]\n",
      "Rmse 1714.0674997754647\n",
      "Rmse 1503.2542309738876\n",
      "Rmse 1507.6108878225252\n",
      "Rmse 1597.121594510506\n",
      "Rmse 2089.674269714271\n"
     ]
    }
   ],
   "source": [
    "pf = pd.DataFrame([])\n",
    "kfold = KFold(n_splits=5,shuffle=True, random_state=3)\n",
    "results = cross_val_score(reg6, X_train,y_train, scoring='neg_mean_squared_error', cv=kfold)\n",
    "print(results)\n",
    "for i,j in enumerate(results):\n",
    "    rmse_=np.sqrt(-results[i].mean())\n",
    "    pf.append(pd.DataFrame({'i_min': i,'rmse_min':rmse_}, index=[0]), ignore_index=True)\n",
    "    print(\"Rmse\",rmse_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
